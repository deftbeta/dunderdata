{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning\n",
    "All the machine learning models contain hyper-parameters than you can tune (as if they were knobs on a guitar) to change the form of your model. For instance, a [decision tree classifier][1] has many hyper-parameters, some of which are:\n",
    "\n",
    "* **criterion** : Measures quality of the split - default is mean squared error, can also be mean absolute error\n",
    "* **max_depth** : The maximum depth of the tree. Default is to continue making splits until node is pure\n",
    "* **min_samples_split** : The minimum number of samples required to split an internal node - default is 2\n",
    "* **min_samples_leaf** : The minimum number of samples required to be at a leaf node. Default is 1\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters vs Parameters\n",
    "Hyper-parameters are all the knobs that you have control over. You set them during **instantiation**. Many of these models have \"normal\" parameters that are fit during **training**. These parameters are completely different than hyper-parameters. The algorithm will find the optimal value of these parameters based on the evaluation metric that is uses. For instance, in a linear regression, the normal parameters are the slope and intercept.\n",
    "\n",
    "Hyper-parameters never change after you have instantiated your model. \n",
    "\n",
    "In a decision tree, a hyper-parameter such as **`max_depth`** dictates the maximum depth of the tree. The algorithm is allowed to use only these many levels. The location of where and how the splits take place is learned through the model and can be thought of as a normal parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "      <th>rest_bp</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>sugar</th>\n",
       "      <th>rest_ekg</th>\n",
       "      <th>chol</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate</th>\n",
       "      <th>angina</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>female</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>male</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slope               thal  rest_bp  chest_pain  num_major_vessels  sugar  \\\n",
       "0      1             normal      128           2                  0      0   \n",
       "1      2             normal      110           3                  0      0   \n",
       "2      1             normal      125           4                  3      0   \n",
       "3      1  reversible_defect      152           4                  0      0   \n",
       "4      3  reversible_defect      178           1                  0      0   \n",
       "\n",
       "   rest_ekg  chol  oldpeak     sex  age  max_heart_rate  angina  disease  \n",
       "0         2   308      0.0    male   45             170       0        0  \n",
       "1         0   214      1.6  female   54             158       0        0  \n",
       "2         2   304      0.0    male   77             162       1        1  \n",
       "3         0   223      0.0    male   40             181       0        1  \n",
       "4         2   270      4.2    male   59             145       0        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "heart = pd.read_csv('data/heart.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart['max_heart_rate'].values\n",
    "X = X.reshape(-1, 1)\n",
    "y = heart['disease'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtr = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76111111111111107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction for every single possible integer heart rate\n",
    "The **`arange`** function creates a single dimensional numpy array with start, stop, and step parameters. You must turn this into a 2-dimensional array. NumPy suggests the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96],\n",
       "       [ 97],\n",
       "       [ 98],\n",
       "       [ 99],\n",
       "       [100]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(X.min(), X.max())\n",
    "x = x.reshape(-1, 1)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dtr.predict(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the original data along with the prediction\n",
    "With linear regression, we had a parameterized model where we could easily plot a line from based on the intercept and slope. With a decision tree, there isn't such a simple mapping from input to output. You would have to traverse the tree to find the end node to get the output value. \n",
    "\n",
    "Thankfully, an easy solution to plotting the model exists and that is to simply plot the prediction for each value of x within the possible range of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b95b358>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAF3CAYAAACFTdwtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDhDUAAAAQAcIagAAAKADBDUAAADQgf8Pj1SeJwxK9tEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = heart.plot(kind='scatter', x='max_heart_rate', y='disease', figsize=(12, 6))\n",
    "ax.plot(x, y_pred, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Overfitting\n",
    "We can clearly see that the model is memorizing the data. By default, the decision tree **`max_depth`** hyper-parameter is set to **`None`**, which the documentation says it continues to make new splits until all nodes are \"pure\". **Pure** meaning that all values are the same in each node. i.e. all the people have the same value for disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tree object\n",
    "Scikit-learn returns the tree object to us as the **`tree_`** attribute. Let's assign it to its own variable and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dtr.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cross Validation to determine how well this model would work in the real world\n",
    "Let's use the **`cross_val_score`** helper function to do cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47222222,  0.52777778,  0.5       ,  0.41666667,  0.55555556])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dtr, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49444444444444446, 0.047790695928014597)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow, that was extremely bad\n",
    "The R-squared dropped a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Let's tune our decision tree to make it better. Create a new decision tree instance, but this time change the **`max_dept`** parameter and output the mean and standard deviation of your cross validation scores. Continue to tune this parameter until you believe you have found the best value for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OutputCodeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc3 = DecisionTreeClassifier(max_depth=5, min_samples_split=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52777778,  0.58333333,  0.58333333,  0.58333333,  0.66666667])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_val_score(dtc3, X, y, cv=kf)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = OutputCodeClassifier(dtc3, code_size = .25, random_state=3, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 180)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 0]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 180)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutputCodeClassifier(code_size=0.25,\n",
       "           estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=25,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "           n_jobs=10, random_state=3)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ.fit(X,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170],\n",
       "       [158],\n",
       "       [162],\n",
       "       [181],\n",
       "       [145],\n",
       "       [150],\n",
       "       [157],\n",
       "       [112],\n",
       "       [140],\n",
       "       [158]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 0]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 180)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-94fa6e854f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mocc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_predict_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_book_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mpaired_distances\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mbetweens\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_norm_squared\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 110\u001b[0;31m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m    111\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[1;32m    112\u001b[0m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "occ.score(X,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = cross_val_score(dtc3, X, y, cv=)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Can you make a simple scatterplot of depth vs cross validation score. Use at least 20 depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning another hyper-parameter\n",
    "It looks like a good choice for depth is somewhere between 2 and 5. Let's tune the **`min_samples_split`** parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1, 32)\n",
    "splits = np.arange(2, 20)\n",
    "\n",
    "all_scores = np.zeros((len(depths), len(splits)))\n",
    "for i, depth in enumerate(depths):\n",
    "    for j, split in enumerate(splits):\n",
    "        dtr = DecisionTreeClassifier(max_depth=depth, min_samples_split=split)\n",
    "        scores = cross_val_score(dtr, X, y)\n",
    "        all_scores[i, j] = scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a heatmap to visualize combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10fd84390>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAAHVCAYAAACpCqAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJS/b/A7w18gaQ/9kIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fd73a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(all_scores, ax=ax, xticklabels=splits, yticklabels=depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is tedious when trying to find optimal hyper-parameters\n",
    "We could continue to nest our for loops for each new hyper-parameter, but that would quickly get out of control. Let's go ahead and save this as our 'final' model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_final_manual = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement over default\n",
    "Remember, the default decision tree massively overfit the data and yielded an R2 of only .18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let Scikit-Learn do this\n",
    "There is a **meta-estimator** called **`GridSearchCV`** which is part of the **`model_selection`** module that will do an exhaustive search of your given hyper-parameter space, do cross validation, and find the best hyper-parameters.\n",
    "\n",
    "\n",
    "### Meta-Estimator?\n",
    "**`GridSearchCV`** is not a machine learning model, but it's usage is similar to all the other Scikit-Learn estimators, except with it, you must pass it the model you want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a dictionary to map hyper-parameter name to possible values\n",
    "To use **`GridSearch`**, you must create a Python dictionary that uses hyper-parameter string names as the keys that map to a list/array of the possible values you want it to search. We can use the same values for depth and splits as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1, 32)\n",
    "splits = np.arange(2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': depths, \n",
    "              'min_samples_split': splits}\n",
    "\n",
    "#creates a python dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeClassifier()\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "gs = GridSearchCV(dtr, param_grid=param_grid, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each combination of depth and split, a decision tree will be fit and cross validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]), 'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_split': 9}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60555555555555551"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results from our grid search object\n",
    "Drill into the grid search object and find the best score and hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All results are stored in `cv_results_` attribute\n",
    "The **`cv_results_`** is a dictionary containing a massive amount of result data from the grid search. It has data on the time it took to fit the model, time it took to score the model, the scores on each cross validated section, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best trained estimator back\n",
    "You don't have to retrain the model after you know what the best parameters are. The **`GridSearchCV`** object provides you the best estimator with the **`best_estimator_`** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_best_gs = gs.best_estimator_\n",
    "dtr_best_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By default the best estimator has been trained on the full dataset\n",
    "The best estimator that gets returned has been re-fit on ALL of the training data. So, after validation, and discovering which combination of parameters worked best. The entire dataset is used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching is computationally expensive. Search area can explode\n",
    "Grid searching is doing a tremendous amount of work. First off, it searches all combinations of the hyper-parameter space that you supply it with. This alone can add up quickly. If you have 10 choices of values for each of 3 different hyper-parameters, the grid search would have to run 1,000 different models.\n",
    "\n",
    "Additionally, the grid search is doing cross validation (that's why its name ends in **`CV`**). You can easily create several hours of work for your machine with a fairly simple grid search.\n",
    "\n",
    "One idea to limit computation time is to limit your grid searching to a smaller subset of the hyper-parameters. Optimize them first and then run another grid search with those newly optimized hyper-parameters set. Here is an example where we set the max depth as a single combination in our parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [3], \n",
    "              'min_samples_split': splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3], 'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1 = GridSearchCV(dtr, param_grid=param_grid)\n",
    "gs1.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 2},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 3},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 4},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 5},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 6},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 7},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 8},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 9},\n",
       " mean: -0.00525, std: 0.03494, params: {'max_depth': 3, 'min_samples_split': 10},\n",
       " mean: 0.00042, std: 0.03426, params: {'max_depth': 3, 'min_samples_split': 11},\n",
       " mean: 0.00404, std: 0.03871, params: {'max_depth': 3, 'min_samples_split': 12},\n",
       " mean: 0.00404, std: 0.03871, params: {'max_depth': 3, 'min_samples_split': 13},\n",
       " mean: 0.00404, std: 0.03871, params: {'max_depth': 3, 'min_samples_split': 14},\n",
       " mean: 0.00217, std: 0.04097, params: {'max_depth': 3, 'min_samples_split': 15},\n",
       " mean: 0.00217, std: 0.04097, params: {'max_depth': 3, 'min_samples_split': 16},\n",
       " mean: 0.00217, std: 0.04097, params: {'max_depth': 3, 'min_samples_split': 17},\n",
       " mean: 0.00217, std: 0.04097, params: {'max_depth': 3, 'min_samples_split': 18},\n",
       " mean: 0.00217, std: 0.04097, params: {'max_depth': 3, 'min_samples_split': 19}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000658</td>\n",
       "      <td>3.209329e-04</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2.234878e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>2.411448e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>1.048066e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>4.975845e-05</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>5.433818e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>3.160010e-05</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>1.484182e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 5}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000570</td>\n",
       "      <td>1.712442e-04</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>1.386821e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 6}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>9.854045e-06</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>2.461422e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 7}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>1.452388e-04</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>1.032261e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 8}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>1.601023e-05</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>3.648973e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 9}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.549537e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>2.165208e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 10}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>3.154940e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>5.411629e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 11}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>6.695402e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>3.619335e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 12}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.275929e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>2.343789e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 13}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>9.584308e-07</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 14}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.274146e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>7.921814e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 15}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000292</td>\n",
       "      <td>3.049127e-05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>6.622762e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 16}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.333559e-05</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>8.395585e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 17}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>8.495734e-06</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1.148376e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 18}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000266</td>\n",
       "      <td>7.136645e-07</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3.814697e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 19}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>1.729809e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.609988e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>3.994063e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.040336e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>1.844318e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>4.909339e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000291</td>\n",
       "      <td>2.025879e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>4.002593e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 5}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.373755e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 6}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000284</td>\n",
       "      <td>6.670609e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>5.383405e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 7}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.945122e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>9.702201e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 8}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>8.203817e-07</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.158233e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 9}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>4.515122e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.591522e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 10}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>3.413968e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.386932e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 11}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>2.968670e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.617033e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 12}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.072619e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.284809e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 13}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.000368</td>\n",
       "      <td>4.673067e-05</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>7.126124e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 8}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>4.685638e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>1.619843e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 9}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0.000337</td>\n",
       "      <td>4.496956e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.577637e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>6.637121e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>3.461588e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 11}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.008099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>9.307001e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2.533976e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 12}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>5.055373e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>3.918778e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 13}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>2.951795e-05</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.148376e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 14}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.036021e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.571394e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 15}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>5.895065e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.186945e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 16}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>7.424892e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>9.584308e-07</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 17}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>9.266604e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.545236e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 18}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>6.435359e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.164108e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 19}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>4.695333e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>3.872082e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 2}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.781944</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>4.537726e-06</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>4.711769e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 3}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.776389</td>\n",
       "      <td>0.012729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.000353</td>\n",
       "      <td>5.356730e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>3.576597e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 4}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>514</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.776389</td>\n",
       "      <td>0.012729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.324406e-05</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>4.386902e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 5}</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>433</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>4.577637e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.119608e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 6}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.773611</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>1.623321e-05</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.293627e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 7}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.053863</td>\n",
       "      <td>409</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.773611</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>5.339725e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.218325e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 8}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.000337</td>\n",
       "      <td>3.495577e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.112166e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 9}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.894332e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>4.539730e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 10}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.791205e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.964605e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 11}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.008099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>5.930060e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>5.106835e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 12}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>4.266560e-06</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>5.626678e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 13}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>7.499240e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.229091e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 14}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>5.898921e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>4.797844e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 15}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>5.551417e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>9.655217e-07</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 16}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>7.373882e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>5.541168e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 17}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>1.028090e-05</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>4.450196e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 18}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.000320</td>\n",
       "      <td>7.331517e-06</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.537754e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 19}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.000658  3.209329e-04         0.000432    2.234878e-04   \n",
       "1         0.000343  2.411448e-05         0.000245    1.048066e-05   \n",
       "2         0.000354  4.975845e-05         0.000267    5.433818e-05   \n",
       "3         0.000338  3.160010e-05         0.000248    1.484182e-05   \n",
       "4         0.000570  1.712442e-04         0.000431    1.386821e-04   \n",
       "5         0.000327  9.854045e-06         0.000253    2.461422e-05   \n",
       "6         0.000437  1.452388e-04         0.000323    1.032261e-04   \n",
       "7         0.000282  1.601023e-05         0.000226    3.648973e-06   \n",
       "8         0.000269  1.549537e-06         0.000235    2.165208e-05   \n",
       "9         0.000286  3.154940e-05         0.000231    5.411629e-06   \n",
       "10        0.000302  6.695402e-05         0.000245    3.619335e-05   \n",
       "11        0.000269  1.275929e-06         0.000227    2.343789e-06   \n",
       "12        0.000268  9.584308e-07         0.000226    6.810597e-07   \n",
       "13        0.000269  1.274146e-06         0.000226    7.921814e-07   \n",
       "14        0.000292  3.049127e-05         0.000268    6.622762e-05   \n",
       "15        0.000276  1.333559e-05         0.000227    8.395585e-07   \n",
       "16        0.000271  8.495734e-06         0.000225    1.148376e-06   \n",
       "17        0.000266  7.136645e-07         0.000225    3.814697e-07   \n",
       "18        0.000280  1.729809e-06         0.000227    1.609988e-06   \n",
       "19        0.000281  3.994063e-06         0.000228    1.040336e-06   \n",
       "20        0.000280  1.844318e-06         0.000226    4.909339e-07   \n",
       "21        0.000291  2.025879e-05         0.000231    4.002593e-06   \n",
       "22        0.000281  1.373755e-06         0.000227    6.810597e-07   \n",
       "23        0.000284  6.670609e-06         0.000233    5.383405e-06   \n",
       "24        0.000281  1.945122e-06         0.000228    9.702201e-07   \n",
       "25        0.000281  8.203817e-07         0.000228    1.158233e-06   \n",
       "26        0.000282  4.515122e-06         0.000227    1.591522e-06   \n",
       "27        0.000282  3.413968e-06         0.000228    1.386932e-06   \n",
       "28        0.000282  2.968670e-06         0.000228    1.617033e-06   \n",
       "29        0.000281  1.072619e-06         0.000227    1.284809e-06   \n",
       "..             ...           ...              ...             ...   \n",
       "528       0.000368  4.673067e-05         0.000244    7.126124e-06   \n",
       "529       0.000340  4.685638e-06         0.000233    1.619843e-06   \n",
       "530       0.000337  4.496956e-06         0.000234    4.577637e-06   \n",
       "531       0.000334  6.637121e-06         0.000233    3.461588e-06   \n",
       "532       0.000341  9.307001e-06         0.000234    2.533976e-06   \n",
       "533       0.000327  5.055373e-06         0.000233    3.918778e-06   \n",
       "534       0.000347  2.951795e-05         0.000235    1.148376e-06   \n",
       "535       0.000328  1.036021e-05         0.000231    1.571394e-06   \n",
       "536       0.000322  5.895065e-06         0.000233    4.186945e-06   \n",
       "537       0.000324  7.424892e-06         0.000231    9.584308e-07   \n",
       "538       0.000322  9.266604e-06         0.000234    4.545236e-06   \n",
       "539       0.000321  6.435359e-06         0.000232    1.164108e-06   \n",
       "540       0.000357  4.695333e-06         0.000235    3.872082e-06   \n",
       "541       0.000357  4.537726e-06         0.000237    4.711769e-06   \n",
       "542       0.000353  5.356730e-06         0.000235    3.576597e-06   \n",
       "543       0.000361  1.324406e-05         0.000235    4.386902e-06   \n",
       "544       0.000345  4.577637e-06         0.000233    4.119608e-06   \n",
       "545       0.000352  1.623321e-05         0.000232    1.293627e-06   \n",
       "546       0.000344  5.339725e-06         0.000234    4.218325e-06   \n",
       "547       0.000337  3.495577e-06         0.000231    1.112166e-06   \n",
       "548       0.000335  3.894332e-06         0.000235    4.539730e-06   \n",
       "549       0.000333  4.791205e-06         0.000233    4.964605e-06   \n",
       "550       0.000328  5.930060e-06         0.000235    5.106835e-06   \n",
       "551       0.000328  4.266560e-06         0.000236    5.626678e-06   \n",
       "552       0.000325  7.499240e-06         0.000233    4.229091e-06   \n",
       "553       0.000324  5.898921e-06         0.000232    4.797844e-06   \n",
       "554       0.000323  5.551417e-06         0.000231    9.655217e-07   \n",
       "555       0.000321  7.373882e-06         0.000232    5.541168e-06   \n",
       "556       0.000323  1.028090e-05         0.000232    4.450196e-06   \n",
       "557       0.000320  7.331517e-06         0.000229    1.537754e-06   \n",
       "\n",
       "    param_max_depth param_min_samples_split  \\\n",
       "0                 1                       2   \n",
       "1                 1                       3   \n",
       "2                 1                       4   \n",
       "3                 1                       5   \n",
       "4                 1                       6   \n",
       "5                 1                       7   \n",
       "6                 1                       8   \n",
       "7                 1                       9   \n",
       "8                 1                      10   \n",
       "9                 1                      11   \n",
       "10                1                      12   \n",
       "11                1                      13   \n",
       "12                1                      14   \n",
       "13                1                      15   \n",
       "14                1                      16   \n",
       "15                1                      17   \n",
       "16                1                      18   \n",
       "17                1                      19   \n",
       "18                2                       2   \n",
       "19                2                       3   \n",
       "20                2                       4   \n",
       "21                2                       5   \n",
       "22                2                       6   \n",
       "23                2                       7   \n",
       "24                2                       8   \n",
       "25                2                       9   \n",
       "26                2                      10   \n",
       "27                2                      11   \n",
       "28                2                      12   \n",
       "29                2                      13   \n",
       "..              ...                     ...   \n",
       "528              30                       8   \n",
       "529              30                       9   \n",
       "530              30                      10   \n",
       "531              30                      11   \n",
       "532              30                      12   \n",
       "533              30                      13   \n",
       "534              30                      14   \n",
       "535              30                      15   \n",
       "536              30                      16   \n",
       "537              30                      17   \n",
       "538              30                      18   \n",
       "539              30                      19   \n",
       "540              31                       2   \n",
       "541              31                       3   \n",
       "542              31                       4   \n",
       "543              31                       5   \n",
       "544              31                       6   \n",
       "545              31                       7   \n",
       "546              31                       8   \n",
       "547              31                       9   \n",
       "548              31                      10   \n",
       "549              31                      11   \n",
       "550              31                      12   \n",
       "551              31                      13   \n",
       "552              31                      14   \n",
       "553              31                      15   \n",
       "554              31                      16   \n",
       "555              31                      17   \n",
       "556              31                      18   \n",
       "557              31                      19   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0      {'max_depth': 1, 'min_samples_split': 2}           0.638889   \n",
       "1      {'max_depth': 1, 'min_samples_split': 3}           0.638889   \n",
       "2      {'max_depth': 1, 'min_samples_split': 4}           0.638889   \n",
       "3      {'max_depth': 1, 'min_samples_split': 5}           0.638889   \n",
       "4      {'max_depth': 1, 'min_samples_split': 6}           0.638889   \n",
       "5      {'max_depth': 1, 'min_samples_split': 7}           0.638889   \n",
       "6      {'max_depth': 1, 'min_samples_split': 8}           0.638889   \n",
       "7      {'max_depth': 1, 'min_samples_split': 9}           0.638889   \n",
       "8     {'max_depth': 1, 'min_samples_split': 10}           0.638889   \n",
       "9     {'max_depth': 1, 'min_samples_split': 11}           0.638889   \n",
       "10    {'max_depth': 1, 'min_samples_split': 12}           0.638889   \n",
       "11    {'max_depth': 1, 'min_samples_split': 13}           0.638889   \n",
       "12    {'max_depth': 1, 'min_samples_split': 14}           0.638889   \n",
       "13    {'max_depth': 1, 'min_samples_split': 15}           0.638889   \n",
       "14    {'max_depth': 1, 'min_samples_split': 16}           0.638889   \n",
       "15    {'max_depth': 1, 'min_samples_split': 17}           0.638889   \n",
       "16    {'max_depth': 1, 'min_samples_split': 18}           0.638889   \n",
       "17    {'max_depth': 1, 'min_samples_split': 19}           0.638889   \n",
       "18     {'max_depth': 2, 'min_samples_split': 2}           0.638889   \n",
       "19     {'max_depth': 2, 'min_samples_split': 3}           0.638889   \n",
       "20     {'max_depth': 2, 'min_samples_split': 4}           0.638889   \n",
       "21     {'max_depth': 2, 'min_samples_split': 5}           0.638889   \n",
       "22     {'max_depth': 2, 'min_samples_split': 6}           0.638889   \n",
       "23     {'max_depth': 2, 'min_samples_split': 7}           0.638889   \n",
       "24     {'max_depth': 2, 'min_samples_split': 8}           0.638889   \n",
       "25     {'max_depth': 2, 'min_samples_split': 9}           0.638889   \n",
       "26    {'max_depth': 2, 'min_samples_split': 10}           0.638889   \n",
       "27    {'max_depth': 2, 'min_samples_split': 11}           0.638889   \n",
       "28    {'max_depth': 2, 'min_samples_split': 12}           0.638889   \n",
       "29    {'max_depth': 2, 'min_samples_split': 13}           0.638889   \n",
       "..                                          ...                ...   \n",
       "528   {'max_depth': 30, 'min_samples_split': 8}           0.666667   \n",
       "529   {'max_depth': 30, 'min_samples_split': 9}           0.666667   \n",
       "530  {'max_depth': 30, 'min_samples_split': 10}           0.666667   \n",
       "531  {'max_depth': 30, 'min_samples_split': 11}           0.611111   \n",
       "532  {'max_depth': 30, 'min_samples_split': 12}           0.611111   \n",
       "533  {'max_depth': 30, 'min_samples_split': 13}           0.583333   \n",
       "534  {'max_depth': 30, 'min_samples_split': 14}           0.583333   \n",
       "535  {'max_depth': 30, 'min_samples_split': 15}           0.583333   \n",
       "536  {'max_depth': 30, 'min_samples_split': 16}           0.583333   \n",
       "537  {'max_depth': 30, 'min_samples_split': 17}           0.583333   \n",
       "538  {'max_depth': 30, 'min_samples_split': 18}           0.611111   \n",
       "539  {'max_depth': 30, 'min_samples_split': 19}           0.611111   \n",
       "540   {'max_depth': 31, 'min_samples_split': 2}           0.527778   \n",
       "541   {'max_depth': 31, 'min_samples_split': 3}           0.527778   \n",
       "542   {'max_depth': 31, 'min_samples_split': 4}           0.527778   \n",
       "543   {'max_depth': 31, 'min_samples_split': 5}           0.555556   \n",
       "544   {'max_depth': 31, 'min_samples_split': 6}           0.583333   \n",
       "545   {'max_depth': 31, 'min_samples_split': 7}           0.583333   \n",
       "546   {'max_depth': 31, 'min_samples_split': 8}           0.666667   \n",
       "547   {'max_depth': 31, 'min_samples_split': 9}           0.666667   \n",
       "548  {'max_depth': 31, 'min_samples_split': 10}           0.666667   \n",
       "549  {'max_depth': 31, 'min_samples_split': 11}           0.611111   \n",
       "550  {'max_depth': 31, 'min_samples_split': 12}           0.611111   \n",
       "551  {'max_depth': 31, 'min_samples_split': 13}           0.583333   \n",
       "552  {'max_depth': 31, 'min_samples_split': 14}           0.583333   \n",
       "553  {'max_depth': 31, 'min_samples_split': 15}           0.583333   \n",
       "554  {'max_depth': 31, 'min_samples_split': 16}           0.583333   \n",
       "555  {'max_depth': 31, 'min_samples_split': 17}           0.583333   \n",
       "556  {'max_depth': 31, 'min_samples_split': 18}           0.611111   \n",
       "557  {'max_depth': 31, 'min_samples_split': 19}           0.611111   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.527778           0.666667           0.527778   \n",
       "1             0.527778           0.666667           0.527778   \n",
       "2             0.527778           0.666667           0.527778   \n",
       "3             0.527778           0.666667           0.527778   \n",
       "4             0.527778           0.666667           0.527778   \n",
       "5             0.527778           0.666667           0.527778   \n",
       "6             0.527778           0.666667           0.527778   \n",
       "7             0.527778           0.666667           0.527778   \n",
       "8             0.527778           0.666667           0.527778   \n",
       "9             0.527778           0.666667           0.527778   \n",
       "10            0.527778           0.666667           0.527778   \n",
       "11            0.527778           0.666667           0.527778   \n",
       "12            0.527778           0.666667           0.527778   \n",
       "13            0.527778           0.666667           0.527778   \n",
       "14            0.527778           0.666667           0.527778   \n",
       "15            0.527778           0.666667           0.527778   \n",
       "16            0.527778           0.666667           0.527778   \n",
       "17            0.527778           0.666667           0.527778   \n",
       "18            0.527778           0.666667           0.527778   \n",
       "19            0.527778           0.666667           0.527778   \n",
       "20            0.527778           0.666667           0.527778   \n",
       "21            0.527778           0.666667           0.527778   \n",
       "22            0.527778           0.666667           0.527778   \n",
       "23            0.527778           0.666667           0.527778   \n",
       "24            0.527778           0.666667           0.527778   \n",
       "25            0.527778           0.666667           0.527778   \n",
       "26            0.527778           0.666667           0.527778   \n",
       "27            0.527778           0.666667           0.527778   \n",
       "28            0.527778           0.666667           0.527778   \n",
       "29            0.527778           0.666667           0.527778   \n",
       "..                 ...                ...                ...   \n",
       "528           0.500000           0.638889           0.583333   \n",
       "529           0.500000           0.638889           0.583333   \n",
       "530           0.500000           0.638889           0.583333   \n",
       "531           0.500000           0.638889           0.583333   \n",
       "532           0.500000           0.638889           0.583333   \n",
       "533           0.500000           0.638889           0.583333   \n",
       "534           0.500000           0.638889           0.583333   \n",
       "535           0.500000           0.638889           0.583333   \n",
       "536           0.527778           0.666667           0.583333   \n",
       "537           0.527778           0.666667           0.583333   \n",
       "538           0.444444           0.666667           0.583333   \n",
       "539           0.444444           0.666667           0.583333   \n",
       "540           0.500000           0.611111           0.527778   \n",
       "541           0.500000           0.611111           0.527778   \n",
       "542           0.500000           0.611111           0.527778   \n",
       "543           0.500000           0.611111           0.527778   \n",
       "544           0.500000           0.583333           0.527778   \n",
       "545           0.500000           0.638889           0.527778   \n",
       "546           0.500000           0.638889           0.583333   \n",
       "547           0.500000           0.638889           0.583333   \n",
       "548           0.500000           0.638889           0.583333   \n",
       "549           0.500000           0.638889           0.583333   \n",
       "550           0.500000           0.638889           0.583333   \n",
       "551           0.500000           0.638889           0.583333   \n",
       "552           0.500000           0.638889           0.583333   \n",
       "553           0.500000           0.638889           0.583333   \n",
       "554           0.527778           0.666667           0.583333   \n",
       "555           0.527778           0.666667           0.583333   \n",
       "556           0.444444           0.666667           0.583333   \n",
       "557           0.444444           0.666667           0.583333   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0             0.638889         0.600000        0.059835                5   \n",
       "1             0.638889         0.600000        0.059835                5   \n",
       "2             0.638889         0.600000        0.059835                5   \n",
       "3             0.638889         0.600000        0.059835                5   \n",
       "4             0.638889         0.600000        0.059835                5   \n",
       "5             0.638889         0.600000        0.059835                5   \n",
       "6             0.638889         0.600000        0.059835                5   \n",
       "7             0.638889         0.600000        0.059835                5   \n",
       "8             0.638889         0.600000        0.059835                5   \n",
       "9             0.638889         0.600000        0.059835                5   \n",
       "10            0.638889         0.600000        0.059835                5   \n",
       "11            0.638889         0.600000        0.059835                5   \n",
       "12            0.638889         0.600000        0.059835                5   \n",
       "13            0.638889         0.600000        0.059835                5   \n",
       "14            0.638889         0.600000        0.059835                5   \n",
       "15            0.638889         0.600000        0.059835                5   \n",
       "16            0.638889         0.600000        0.059835                5   \n",
       "17            0.638889         0.600000        0.059835                5   \n",
       "18            0.638889         0.600000        0.059835                5   \n",
       "19            0.638889         0.600000        0.059835                5   \n",
       "20            0.638889         0.600000        0.059835                5   \n",
       "21            0.638889         0.600000        0.059835                5   \n",
       "22            0.638889         0.600000        0.059835                5   \n",
       "23            0.638889         0.600000        0.059835                5   \n",
       "24            0.638889         0.600000        0.059835                5   \n",
       "25            0.638889         0.600000        0.059835                5   \n",
       "26            0.638889         0.600000        0.059835                5   \n",
       "27            0.638889         0.600000        0.059835                5   \n",
       "28            0.638889         0.600000        0.059835                5   \n",
       "29            0.638889         0.600000        0.059835                5   \n",
       "..                 ...              ...             ...              ...   \n",
       "528           0.500000         0.577778        0.068943              163   \n",
       "529           0.555556         0.588889        0.059317               53   \n",
       "530           0.555556         0.588889        0.059317               53   \n",
       "531           0.555556         0.577778        0.047791              163   \n",
       "532           0.555556         0.577778        0.047791              163   \n",
       "533           0.555556         0.572222        0.045134              267   \n",
       "534           0.555556         0.572222        0.045134              267   \n",
       "535           0.555556         0.572222        0.045134              267   \n",
       "536           0.555556         0.583333        0.046481              110   \n",
       "537           0.555556         0.583333        0.046481              110   \n",
       "538           0.555556         0.572222        0.073703              267   \n",
       "539           0.555556         0.572222        0.073703              267   \n",
       "540           0.527778         0.538889        0.037680              433   \n",
       "541           0.527778         0.538889        0.037680              433   \n",
       "542           0.500000         0.533333        0.040825              514   \n",
       "543           0.500000         0.538889        0.041574              433   \n",
       "544           0.500000         0.538889        0.037680              433   \n",
       "545           0.500000         0.550000        0.053863              409   \n",
       "546           0.500000         0.577778        0.068943              163   \n",
       "547           0.555556         0.588889        0.059317               53   \n",
       "548           0.555556         0.588889        0.059317               53   \n",
       "549           0.555556         0.577778        0.047791              163   \n",
       "550           0.555556         0.577778        0.047791              163   \n",
       "551           0.555556         0.572222        0.045134              267   \n",
       "552           0.555556         0.572222        0.045134              267   \n",
       "553           0.555556         0.572222        0.045134              267   \n",
       "554           0.555556         0.583333        0.046481              110   \n",
       "555           0.555556         0.583333        0.046481              110   \n",
       "556           0.555556         0.572222        0.073703              267   \n",
       "557           0.555556         0.572222        0.073703              267   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.673611            0.666667            0.680556   \n",
       "1              0.673611            0.666667            0.680556   \n",
       "2              0.673611            0.666667            0.680556   \n",
       "3              0.673611            0.666667            0.680556   \n",
       "4              0.673611            0.666667            0.680556   \n",
       "5              0.673611            0.666667            0.680556   \n",
       "6              0.673611            0.666667            0.680556   \n",
       "7              0.673611            0.666667            0.680556   \n",
       "8              0.673611            0.666667            0.680556   \n",
       "9              0.673611            0.666667            0.680556   \n",
       "10             0.673611            0.666667            0.680556   \n",
       "11             0.673611            0.666667            0.680556   \n",
       "12             0.673611            0.666667            0.680556   \n",
       "13             0.673611            0.666667            0.680556   \n",
       "14             0.673611            0.666667            0.680556   \n",
       "15             0.673611            0.666667            0.680556   \n",
       "16             0.673611            0.666667            0.680556   \n",
       "17             0.673611            0.666667            0.680556   \n",
       "18             0.673611            0.666667            0.680556   \n",
       "19             0.673611            0.666667            0.680556   \n",
       "20             0.673611            0.666667            0.680556   \n",
       "21             0.673611            0.666667            0.680556   \n",
       "22             0.673611            0.666667            0.680556   \n",
       "23             0.673611            0.666667            0.680556   \n",
       "24             0.673611            0.666667            0.680556   \n",
       "25             0.673611            0.666667            0.680556   \n",
       "26             0.673611            0.666667            0.680556   \n",
       "27             0.673611            0.666667            0.680556   \n",
       "28             0.673611            0.666667            0.680556   \n",
       "29             0.673611            0.666667            0.680556   \n",
       "..                  ...                 ...                 ...   \n",
       "528            0.770833            0.791667            0.756944   \n",
       "529            0.770833            0.777778            0.756944   \n",
       "530            0.770833            0.777778            0.756944   \n",
       "531            0.756944            0.777778            0.756944   \n",
       "532            0.756944            0.770833            0.756944   \n",
       "533            0.743056            0.770833            0.750000   \n",
       "534            0.743056            0.770833            0.750000   \n",
       "535            0.743056            0.770833            0.750000   \n",
       "536            0.743056            0.770833            0.736111   \n",
       "537            0.743056            0.770833            0.736111   \n",
       "538            0.729167            0.763889            0.736111   \n",
       "539            0.729167            0.763889            0.736111   \n",
       "540            0.791667            0.798611            0.770833   \n",
       "541            0.791667            0.791667            0.763889   \n",
       "542            0.791667            0.791667            0.763889   \n",
       "543            0.784722            0.791667            0.763889   \n",
       "544            0.784722            0.791667            0.756944   \n",
       "545            0.784722            0.791667            0.756944   \n",
       "546            0.770833            0.791667            0.756944   \n",
       "547            0.770833            0.777778            0.756944   \n",
       "548            0.770833            0.777778            0.756944   \n",
       "549            0.756944            0.777778            0.756944   \n",
       "550            0.756944            0.770833            0.756944   \n",
       "551            0.743056            0.770833            0.750000   \n",
       "552            0.743056            0.770833            0.750000   \n",
       "553            0.743056            0.770833            0.750000   \n",
       "554            0.743056            0.770833            0.736111   \n",
       "555            0.743056            0.770833            0.736111   \n",
       "556            0.729167            0.763889            0.736111   \n",
       "557            0.729167            0.763889            0.736111   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.715278            0.673611          0.681944         0.017236  \n",
       "1              0.715278            0.673611          0.681944         0.017236  \n",
       "2              0.715278            0.673611          0.681944         0.017236  \n",
       "3              0.715278            0.673611          0.681944         0.017236  \n",
       "4              0.715278            0.673611          0.681944         0.017236  \n",
       "5              0.715278            0.673611          0.681944         0.017236  \n",
       "6              0.715278            0.673611          0.681944         0.017236  \n",
       "7              0.715278            0.673611          0.681944         0.017236  \n",
       "8              0.715278            0.673611          0.681944         0.017236  \n",
       "9              0.715278            0.673611          0.681944         0.017236  \n",
       "10             0.715278            0.673611          0.681944         0.017236  \n",
       "11             0.715278            0.673611          0.681944         0.017236  \n",
       "12             0.715278            0.673611          0.681944         0.017236  \n",
       "13             0.715278            0.673611          0.681944         0.017236  \n",
       "14             0.715278            0.673611          0.681944         0.017236  \n",
       "15             0.715278            0.673611          0.681944         0.017236  \n",
       "16             0.715278            0.673611          0.681944         0.017236  \n",
       "17             0.715278            0.673611          0.681944         0.017236  \n",
       "18             0.715278            0.673611          0.681944         0.017236  \n",
       "19             0.715278            0.673611          0.681944         0.017236  \n",
       "20             0.715278            0.673611          0.681944         0.017236  \n",
       "21             0.715278            0.673611          0.681944         0.017236  \n",
       "22             0.715278            0.673611          0.681944         0.017236  \n",
       "23             0.715278            0.673611          0.681944         0.017236  \n",
       "24             0.715278            0.673611          0.681944         0.017236  \n",
       "25             0.715278            0.673611          0.681944         0.017236  \n",
       "26             0.715278            0.673611          0.681944         0.017236  \n",
       "27             0.715278            0.673611          0.681944         0.017236  \n",
       "28             0.715278            0.673611          0.681944         0.017236  \n",
       "29             0.715278            0.673611          0.681944         0.017236  \n",
       "..                  ...                 ...               ...              ...  \n",
       "528            0.770833            0.763889          0.770833         0.011620  \n",
       "529            0.770833            0.763889          0.768056         0.007082  \n",
       "530            0.770833            0.763889          0.768056         0.007082  \n",
       "531            0.770833            0.763889          0.765278         0.008099  \n",
       "532            0.763889            0.763889          0.762500         0.005197  \n",
       "533            0.763889            0.756944          0.756944         0.009821  \n",
       "534            0.763889            0.756944          0.756944         0.009821  \n",
       "535            0.750000            0.756944          0.754167         0.009420  \n",
       "536            0.750000            0.756944          0.751389         0.011948  \n",
       "537            0.750000            0.756944          0.751389         0.011948  \n",
       "538            0.750000            0.756944          0.747222         0.012880  \n",
       "539            0.750000            0.756944          0.747222         0.012880  \n",
       "540            0.770833            0.777778          0.781944         0.011283  \n",
       "541            0.770833            0.763889          0.776389         0.012729  \n",
       "542            0.770833            0.763889          0.776389         0.012729  \n",
       "543            0.770833            0.763889          0.775000         0.011283  \n",
       "544            0.770833            0.763889          0.773611         0.012880  \n",
       "545            0.770833            0.763889          0.773611         0.012880  \n",
       "546            0.770833            0.763889          0.770833         0.011620  \n",
       "547            0.770833            0.763889          0.768056         0.007082  \n",
       "548            0.770833            0.763889          0.768056         0.007082  \n",
       "549            0.770833            0.763889          0.765278         0.008099  \n",
       "550            0.763889            0.763889          0.762500         0.005197  \n",
       "551            0.763889            0.756944          0.756944         0.009821  \n",
       "552            0.763889            0.756944          0.756944         0.009821  \n",
       "553            0.750000            0.756944          0.754167         0.009420  \n",
       "554            0.750000            0.756944          0.751389         0.011948  \n",
       "555            0.750000            0.756944          0.751389         0.011948  \n",
       "556            0.750000            0.756944          0.747222         0.012880  \n",
       "557            0.750000            0.756944          0.747222         0.012880  \n",
       "\n",
       "[558 rows x 22 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_best_gs = gs.best_estimator_\n",
    "dtr_best_gs\n",
    "\n",
    "#store the model with the best estimator combination for use as your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_best_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Use grid search to on more of the hyper-parameters than just depth and min_samples_split. There are many more to choose from. Keep saving the best estimator to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "gpc = GaussianProcessClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_restarts_optimizer': [10],\n",
    "              'max_iter_predict': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GaussianProcessClassifier(copy_X_train=True, kernel=None,\n",
       "             max_iter_predict=100, multi_class='one_vs_rest', n_jobs=1,\n",
       "             n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
       "             random_state=None, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_restarts_optimizer': [10], 'max_iter_predict': [100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1 = GridSearchCV(gpc, param_grid=param_grid)\n",
    "gs1.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.63333, std: 0.03113, params: {'max_iter_predict': 100, 'n_restarts_optimizer': 10}]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000658</td>\n",
       "      <td>3.209329e-04</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2.234878e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>2.411448e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>1.048066e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>4.975845e-05</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>5.433818e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>3.160010e-05</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>1.484182e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 5}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000570</td>\n",
       "      <td>1.712442e-04</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>1.386821e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 6}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>9.854045e-06</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>2.461422e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 7}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>1.452388e-04</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>1.032261e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 8}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>1.601023e-05</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>3.648973e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 9}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.549537e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>2.165208e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 10}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>3.154940e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>5.411629e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 11}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>6.695402e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>3.619335e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 12}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.275929e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>2.343789e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 13}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>9.584308e-07</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 14}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.274146e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>7.921814e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 15}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000292</td>\n",
       "      <td>3.049127e-05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>6.622762e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 16}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.333559e-05</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>8.395585e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 17}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>8.495734e-06</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1.148376e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 18}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000266</td>\n",
       "      <td>7.136645e-07</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3.814697e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 19}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>1.729809e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.609988e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>3.994063e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.040336e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000280</td>\n",
       "      <td>1.844318e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>4.909339e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000291</td>\n",
       "      <td>2.025879e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>4.002593e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 5}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.373755e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 6}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000284</td>\n",
       "      <td>6.670609e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>5.383405e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 7}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.945122e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>9.702201e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 8}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>8.203817e-07</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.158233e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 9}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>4.515122e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.591522e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 10}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>3.413968e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.386932e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 11}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>2.968670e-06</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.617033e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 12}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.072619e-06</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.284809e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 13}</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.000368</td>\n",
       "      <td>4.673067e-05</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>7.126124e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 8}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>4.685638e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>1.619843e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 9}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0.000337</td>\n",
       "      <td>4.496956e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.577637e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>6.637121e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>3.461588e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 11}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.008099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>9.307001e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2.533976e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 12}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>5.055373e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>3.918778e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 13}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>2.951795e-05</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.148376e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 14}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.036021e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.571394e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 15}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>5.895065e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.186945e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 16}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>7.424892e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>9.584308e-07</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 17}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>9.266604e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.545236e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 18}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>6.435359e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.164108e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 19}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>4.695333e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>3.872082e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 2}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.781944</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>4.537726e-06</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>4.711769e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 3}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.776389</td>\n",
       "      <td>0.012729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.000353</td>\n",
       "      <td>5.356730e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>3.576597e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 4}</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>514</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.776389</td>\n",
       "      <td>0.012729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.324406e-05</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>4.386902e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 5}</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>433</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>4.577637e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.119608e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 6}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>433</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.773611</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>1.623321e-05</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.293627e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 7}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.053863</td>\n",
       "      <td>409</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.773611</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>5.339725e-06</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>4.218325e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 8}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.000337</td>\n",
       "      <td>3.495577e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.112166e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 9}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.894332e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>4.539730e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 10}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>53</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.791205e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.964605e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 11}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.765278</td>\n",
       "      <td>0.008099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>5.930060e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>5.106835e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 12}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>163</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>4.266560e-06</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>5.626678e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 13}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>7.499240e-06</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4.229091e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 14}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>5.898921e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>4.797844e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 15}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>267</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>5.551417e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>9.655217e-07</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 16}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>7.373882e-06</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>5.541168e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 17}</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>110</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>1.028090e-05</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>4.450196e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 18}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.000320</td>\n",
       "      <td>7.331517e-06</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1.537754e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_split': 19}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>267</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.012880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.000658  3.209329e-04         0.000432    2.234878e-04   \n",
       "1         0.000343  2.411448e-05         0.000245    1.048066e-05   \n",
       "2         0.000354  4.975845e-05         0.000267    5.433818e-05   \n",
       "3         0.000338  3.160010e-05         0.000248    1.484182e-05   \n",
       "4         0.000570  1.712442e-04         0.000431    1.386821e-04   \n",
       "5         0.000327  9.854045e-06         0.000253    2.461422e-05   \n",
       "6         0.000437  1.452388e-04         0.000323    1.032261e-04   \n",
       "7         0.000282  1.601023e-05         0.000226    3.648973e-06   \n",
       "8         0.000269  1.549537e-06         0.000235    2.165208e-05   \n",
       "9         0.000286  3.154940e-05         0.000231    5.411629e-06   \n",
       "10        0.000302  6.695402e-05         0.000245    3.619335e-05   \n",
       "11        0.000269  1.275929e-06         0.000227    2.343789e-06   \n",
       "12        0.000268  9.584308e-07         0.000226    6.810597e-07   \n",
       "13        0.000269  1.274146e-06         0.000226    7.921814e-07   \n",
       "14        0.000292  3.049127e-05         0.000268    6.622762e-05   \n",
       "15        0.000276  1.333559e-05         0.000227    8.395585e-07   \n",
       "16        0.000271  8.495734e-06         0.000225    1.148376e-06   \n",
       "17        0.000266  7.136645e-07         0.000225    3.814697e-07   \n",
       "18        0.000280  1.729809e-06         0.000227    1.609988e-06   \n",
       "19        0.000281  3.994063e-06         0.000228    1.040336e-06   \n",
       "20        0.000280  1.844318e-06         0.000226    4.909339e-07   \n",
       "21        0.000291  2.025879e-05         0.000231    4.002593e-06   \n",
       "22        0.000281  1.373755e-06         0.000227    6.810597e-07   \n",
       "23        0.000284  6.670609e-06         0.000233    5.383405e-06   \n",
       "24        0.000281  1.945122e-06         0.000228    9.702201e-07   \n",
       "25        0.000281  8.203817e-07         0.000228    1.158233e-06   \n",
       "26        0.000282  4.515122e-06         0.000227    1.591522e-06   \n",
       "27        0.000282  3.413968e-06         0.000228    1.386932e-06   \n",
       "28        0.000282  2.968670e-06         0.000228    1.617033e-06   \n",
       "29        0.000281  1.072619e-06         0.000227    1.284809e-06   \n",
       "..             ...           ...              ...             ...   \n",
       "528       0.000368  4.673067e-05         0.000244    7.126124e-06   \n",
       "529       0.000340  4.685638e-06         0.000233    1.619843e-06   \n",
       "530       0.000337  4.496956e-06         0.000234    4.577637e-06   \n",
       "531       0.000334  6.637121e-06         0.000233    3.461588e-06   \n",
       "532       0.000341  9.307001e-06         0.000234    2.533976e-06   \n",
       "533       0.000327  5.055373e-06         0.000233    3.918778e-06   \n",
       "534       0.000347  2.951795e-05         0.000235    1.148376e-06   \n",
       "535       0.000328  1.036021e-05         0.000231    1.571394e-06   \n",
       "536       0.000322  5.895065e-06         0.000233    4.186945e-06   \n",
       "537       0.000324  7.424892e-06         0.000231    9.584308e-07   \n",
       "538       0.000322  9.266604e-06         0.000234    4.545236e-06   \n",
       "539       0.000321  6.435359e-06         0.000232    1.164108e-06   \n",
       "540       0.000357  4.695333e-06         0.000235    3.872082e-06   \n",
       "541       0.000357  4.537726e-06         0.000237    4.711769e-06   \n",
       "542       0.000353  5.356730e-06         0.000235    3.576597e-06   \n",
       "543       0.000361  1.324406e-05         0.000235    4.386902e-06   \n",
       "544       0.000345  4.577637e-06         0.000233    4.119608e-06   \n",
       "545       0.000352  1.623321e-05         0.000232    1.293627e-06   \n",
       "546       0.000344  5.339725e-06         0.000234    4.218325e-06   \n",
       "547       0.000337  3.495577e-06         0.000231    1.112166e-06   \n",
       "548       0.000335  3.894332e-06         0.000235    4.539730e-06   \n",
       "549       0.000333  4.791205e-06         0.000233    4.964605e-06   \n",
       "550       0.000328  5.930060e-06         0.000235    5.106835e-06   \n",
       "551       0.000328  4.266560e-06         0.000236    5.626678e-06   \n",
       "552       0.000325  7.499240e-06         0.000233    4.229091e-06   \n",
       "553       0.000324  5.898921e-06         0.000232    4.797844e-06   \n",
       "554       0.000323  5.551417e-06         0.000231    9.655217e-07   \n",
       "555       0.000321  7.373882e-06         0.000232    5.541168e-06   \n",
       "556       0.000323  1.028090e-05         0.000232    4.450196e-06   \n",
       "557       0.000320  7.331517e-06         0.000229    1.537754e-06   \n",
       "\n",
       "    param_max_depth param_min_samples_split  \\\n",
       "0                 1                       2   \n",
       "1                 1                       3   \n",
       "2                 1                       4   \n",
       "3                 1                       5   \n",
       "4                 1                       6   \n",
       "5                 1                       7   \n",
       "6                 1                       8   \n",
       "7                 1                       9   \n",
       "8                 1                      10   \n",
       "9                 1                      11   \n",
       "10                1                      12   \n",
       "11                1                      13   \n",
       "12                1                      14   \n",
       "13                1                      15   \n",
       "14                1                      16   \n",
       "15                1                      17   \n",
       "16                1                      18   \n",
       "17                1                      19   \n",
       "18                2                       2   \n",
       "19                2                       3   \n",
       "20                2                       4   \n",
       "21                2                       5   \n",
       "22                2                       6   \n",
       "23                2                       7   \n",
       "24                2                       8   \n",
       "25                2                       9   \n",
       "26                2                      10   \n",
       "27                2                      11   \n",
       "28                2                      12   \n",
       "29                2                      13   \n",
       "..              ...                     ...   \n",
       "528              30                       8   \n",
       "529              30                       9   \n",
       "530              30                      10   \n",
       "531              30                      11   \n",
       "532              30                      12   \n",
       "533              30                      13   \n",
       "534              30                      14   \n",
       "535              30                      15   \n",
       "536              30                      16   \n",
       "537              30                      17   \n",
       "538              30                      18   \n",
       "539              30                      19   \n",
       "540              31                       2   \n",
       "541              31                       3   \n",
       "542              31                       4   \n",
       "543              31                       5   \n",
       "544              31                       6   \n",
       "545              31                       7   \n",
       "546              31                       8   \n",
       "547              31                       9   \n",
       "548              31                      10   \n",
       "549              31                      11   \n",
       "550              31                      12   \n",
       "551              31                      13   \n",
       "552              31                      14   \n",
       "553              31                      15   \n",
       "554              31                      16   \n",
       "555              31                      17   \n",
       "556              31                      18   \n",
       "557              31                      19   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0      {'max_depth': 1, 'min_samples_split': 2}           0.638889   \n",
       "1      {'max_depth': 1, 'min_samples_split': 3}           0.638889   \n",
       "2      {'max_depth': 1, 'min_samples_split': 4}           0.638889   \n",
       "3      {'max_depth': 1, 'min_samples_split': 5}           0.638889   \n",
       "4      {'max_depth': 1, 'min_samples_split': 6}           0.638889   \n",
       "5      {'max_depth': 1, 'min_samples_split': 7}           0.638889   \n",
       "6      {'max_depth': 1, 'min_samples_split': 8}           0.638889   \n",
       "7      {'max_depth': 1, 'min_samples_split': 9}           0.638889   \n",
       "8     {'max_depth': 1, 'min_samples_split': 10}           0.638889   \n",
       "9     {'max_depth': 1, 'min_samples_split': 11}           0.638889   \n",
       "10    {'max_depth': 1, 'min_samples_split': 12}           0.638889   \n",
       "11    {'max_depth': 1, 'min_samples_split': 13}           0.638889   \n",
       "12    {'max_depth': 1, 'min_samples_split': 14}           0.638889   \n",
       "13    {'max_depth': 1, 'min_samples_split': 15}           0.638889   \n",
       "14    {'max_depth': 1, 'min_samples_split': 16}           0.638889   \n",
       "15    {'max_depth': 1, 'min_samples_split': 17}           0.638889   \n",
       "16    {'max_depth': 1, 'min_samples_split': 18}           0.638889   \n",
       "17    {'max_depth': 1, 'min_samples_split': 19}           0.638889   \n",
       "18     {'max_depth': 2, 'min_samples_split': 2}           0.638889   \n",
       "19     {'max_depth': 2, 'min_samples_split': 3}           0.638889   \n",
       "20     {'max_depth': 2, 'min_samples_split': 4}           0.638889   \n",
       "21     {'max_depth': 2, 'min_samples_split': 5}           0.638889   \n",
       "22     {'max_depth': 2, 'min_samples_split': 6}           0.638889   \n",
       "23     {'max_depth': 2, 'min_samples_split': 7}           0.638889   \n",
       "24     {'max_depth': 2, 'min_samples_split': 8}           0.638889   \n",
       "25     {'max_depth': 2, 'min_samples_split': 9}           0.638889   \n",
       "26    {'max_depth': 2, 'min_samples_split': 10}           0.638889   \n",
       "27    {'max_depth': 2, 'min_samples_split': 11}           0.638889   \n",
       "28    {'max_depth': 2, 'min_samples_split': 12}           0.638889   \n",
       "29    {'max_depth': 2, 'min_samples_split': 13}           0.638889   \n",
       "..                                          ...                ...   \n",
       "528   {'max_depth': 30, 'min_samples_split': 8}           0.666667   \n",
       "529   {'max_depth': 30, 'min_samples_split': 9}           0.666667   \n",
       "530  {'max_depth': 30, 'min_samples_split': 10}           0.666667   \n",
       "531  {'max_depth': 30, 'min_samples_split': 11}           0.611111   \n",
       "532  {'max_depth': 30, 'min_samples_split': 12}           0.611111   \n",
       "533  {'max_depth': 30, 'min_samples_split': 13}           0.583333   \n",
       "534  {'max_depth': 30, 'min_samples_split': 14}           0.583333   \n",
       "535  {'max_depth': 30, 'min_samples_split': 15}           0.583333   \n",
       "536  {'max_depth': 30, 'min_samples_split': 16}           0.583333   \n",
       "537  {'max_depth': 30, 'min_samples_split': 17}           0.583333   \n",
       "538  {'max_depth': 30, 'min_samples_split': 18}           0.611111   \n",
       "539  {'max_depth': 30, 'min_samples_split': 19}           0.611111   \n",
       "540   {'max_depth': 31, 'min_samples_split': 2}           0.527778   \n",
       "541   {'max_depth': 31, 'min_samples_split': 3}           0.527778   \n",
       "542   {'max_depth': 31, 'min_samples_split': 4}           0.527778   \n",
       "543   {'max_depth': 31, 'min_samples_split': 5}           0.555556   \n",
       "544   {'max_depth': 31, 'min_samples_split': 6}           0.583333   \n",
       "545   {'max_depth': 31, 'min_samples_split': 7}           0.583333   \n",
       "546   {'max_depth': 31, 'min_samples_split': 8}           0.666667   \n",
       "547   {'max_depth': 31, 'min_samples_split': 9}           0.666667   \n",
       "548  {'max_depth': 31, 'min_samples_split': 10}           0.666667   \n",
       "549  {'max_depth': 31, 'min_samples_split': 11}           0.611111   \n",
       "550  {'max_depth': 31, 'min_samples_split': 12}           0.611111   \n",
       "551  {'max_depth': 31, 'min_samples_split': 13}           0.583333   \n",
       "552  {'max_depth': 31, 'min_samples_split': 14}           0.583333   \n",
       "553  {'max_depth': 31, 'min_samples_split': 15}           0.583333   \n",
       "554  {'max_depth': 31, 'min_samples_split': 16}           0.583333   \n",
       "555  {'max_depth': 31, 'min_samples_split': 17}           0.583333   \n",
       "556  {'max_depth': 31, 'min_samples_split': 18}           0.611111   \n",
       "557  {'max_depth': 31, 'min_samples_split': 19}           0.611111   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.527778           0.666667           0.527778   \n",
       "1             0.527778           0.666667           0.527778   \n",
       "2             0.527778           0.666667           0.527778   \n",
       "3             0.527778           0.666667           0.527778   \n",
       "4             0.527778           0.666667           0.527778   \n",
       "5             0.527778           0.666667           0.527778   \n",
       "6             0.527778           0.666667           0.527778   \n",
       "7             0.527778           0.666667           0.527778   \n",
       "8             0.527778           0.666667           0.527778   \n",
       "9             0.527778           0.666667           0.527778   \n",
       "10            0.527778           0.666667           0.527778   \n",
       "11            0.527778           0.666667           0.527778   \n",
       "12            0.527778           0.666667           0.527778   \n",
       "13            0.527778           0.666667           0.527778   \n",
       "14            0.527778           0.666667           0.527778   \n",
       "15            0.527778           0.666667           0.527778   \n",
       "16            0.527778           0.666667           0.527778   \n",
       "17            0.527778           0.666667           0.527778   \n",
       "18            0.527778           0.666667           0.527778   \n",
       "19            0.527778           0.666667           0.527778   \n",
       "20            0.527778           0.666667           0.527778   \n",
       "21            0.527778           0.666667           0.527778   \n",
       "22            0.527778           0.666667           0.527778   \n",
       "23            0.527778           0.666667           0.527778   \n",
       "24            0.527778           0.666667           0.527778   \n",
       "25            0.527778           0.666667           0.527778   \n",
       "26            0.527778           0.666667           0.527778   \n",
       "27            0.527778           0.666667           0.527778   \n",
       "28            0.527778           0.666667           0.527778   \n",
       "29            0.527778           0.666667           0.527778   \n",
       "..                 ...                ...                ...   \n",
       "528           0.500000           0.638889           0.583333   \n",
       "529           0.500000           0.638889           0.583333   \n",
       "530           0.500000           0.638889           0.583333   \n",
       "531           0.500000           0.638889           0.583333   \n",
       "532           0.500000           0.638889           0.583333   \n",
       "533           0.500000           0.638889           0.583333   \n",
       "534           0.500000           0.638889           0.583333   \n",
       "535           0.500000           0.638889           0.583333   \n",
       "536           0.527778           0.666667           0.583333   \n",
       "537           0.527778           0.666667           0.583333   \n",
       "538           0.444444           0.666667           0.583333   \n",
       "539           0.444444           0.666667           0.583333   \n",
       "540           0.500000           0.611111           0.527778   \n",
       "541           0.500000           0.611111           0.527778   \n",
       "542           0.500000           0.611111           0.527778   \n",
       "543           0.500000           0.611111           0.527778   \n",
       "544           0.500000           0.583333           0.527778   \n",
       "545           0.500000           0.638889           0.527778   \n",
       "546           0.500000           0.638889           0.583333   \n",
       "547           0.500000           0.638889           0.583333   \n",
       "548           0.500000           0.638889           0.583333   \n",
       "549           0.500000           0.638889           0.583333   \n",
       "550           0.500000           0.638889           0.583333   \n",
       "551           0.500000           0.638889           0.583333   \n",
       "552           0.500000           0.638889           0.583333   \n",
       "553           0.500000           0.638889           0.583333   \n",
       "554           0.527778           0.666667           0.583333   \n",
       "555           0.527778           0.666667           0.583333   \n",
       "556           0.444444           0.666667           0.583333   \n",
       "557           0.444444           0.666667           0.583333   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0             0.638889         0.600000        0.059835                5   \n",
       "1             0.638889         0.600000        0.059835                5   \n",
       "2             0.638889         0.600000        0.059835                5   \n",
       "3             0.638889         0.600000        0.059835                5   \n",
       "4             0.638889         0.600000        0.059835                5   \n",
       "5             0.638889         0.600000        0.059835                5   \n",
       "6             0.638889         0.600000        0.059835                5   \n",
       "7             0.638889         0.600000        0.059835                5   \n",
       "8             0.638889         0.600000        0.059835                5   \n",
       "9             0.638889         0.600000        0.059835                5   \n",
       "10            0.638889         0.600000        0.059835                5   \n",
       "11            0.638889         0.600000        0.059835                5   \n",
       "12            0.638889         0.600000        0.059835                5   \n",
       "13            0.638889         0.600000        0.059835                5   \n",
       "14            0.638889         0.600000        0.059835                5   \n",
       "15            0.638889         0.600000        0.059835                5   \n",
       "16            0.638889         0.600000        0.059835                5   \n",
       "17            0.638889         0.600000        0.059835                5   \n",
       "18            0.638889         0.600000        0.059835                5   \n",
       "19            0.638889         0.600000        0.059835                5   \n",
       "20            0.638889         0.600000        0.059835                5   \n",
       "21            0.638889         0.600000        0.059835                5   \n",
       "22            0.638889         0.600000        0.059835                5   \n",
       "23            0.638889         0.600000        0.059835                5   \n",
       "24            0.638889         0.600000        0.059835                5   \n",
       "25            0.638889         0.600000        0.059835                5   \n",
       "26            0.638889         0.600000        0.059835                5   \n",
       "27            0.638889         0.600000        0.059835                5   \n",
       "28            0.638889         0.600000        0.059835                5   \n",
       "29            0.638889         0.600000        0.059835                5   \n",
       "..                 ...              ...             ...              ...   \n",
       "528           0.500000         0.577778        0.068943              163   \n",
       "529           0.555556         0.588889        0.059317               53   \n",
       "530           0.555556         0.588889        0.059317               53   \n",
       "531           0.555556         0.577778        0.047791              163   \n",
       "532           0.555556         0.577778        0.047791              163   \n",
       "533           0.555556         0.572222        0.045134              267   \n",
       "534           0.555556         0.572222        0.045134              267   \n",
       "535           0.555556         0.572222        0.045134              267   \n",
       "536           0.555556         0.583333        0.046481              110   \n",
       "537           0.555556         0.583333        0.046481              110   \n",
       "538           0.555556         0.572222        0.073703              267   \n",
       "539           0.555556         0.572222        0.073703              267   \n",
       "540           0.527778         0.538889        0.037680              433   \n",
       "541           0.527778         0.538889        0.037680              433   \n",
       "542           0.500000         0.533333        0.040825              514   \n",
       "543           0.500000         0.538889        0.041574              433   \n",
       "544           0.500000         0.538889        0.037680              433   \n",
       "545           0.500000         0.550000        0.053863              409   \n",
       "546           0.500000         0.577778        0.068943              163   \n",
       "547           0.555556         0.588889        0.059317               53   \n",
       "548           0.555556         0.588889        0.059317               53   \n",
       "549           0.555556         0.577778        0.047791              163   \n",
       "550           0.555556         0.577778        0.047791              163   \n",
       "551           0.555556         0.572222        0.045134              267   \n",
       "552           0.555556         0.572222        0.045134              267   \n",
       "553           0.555556         0.572222        0.045134              267   \n",
       "554           0.555556         0.583333        0.046481              110   \n",
       "555           0.555556         0.583333        0.046481              110   \n",
       "556           0.555556         0.572222        0.073703              267   \n",
       "557           0.555556         0.572222        0.073703              267   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.673611            0.666667            0.680556   \n",
       "1              0.673611            0.666667            0.680556   \n",
       "2              0.673611            0.666667            0.680556   \n",
       "3              0.673611            0.666667            0.680556   \n",
       "4              0.673611            0.666667            0.680556   \n",
       "5              0.673611            0.666667            0.680556   \n",
       "6              0.673611            0.666667            0.680556   \n",
       "7              0.673611            0.666667            0.680556   \n",
       "8              0.673611            0.666667            0.680556   \n",
       "9              0.673611            0.666667            0.680556   \n",
       "10             0.673611            0.666667            0.680556   \n",
       "11             0.673611            0.666667            0.680556   \n",
       "12             0.673611            0.666667            0.680556   \n",
       "13             0.673611            0.666667            0.680556   \n",
       "14             0.673611            0.666667            0.680556   \n",
       "15             0.673611            0.666667            0.680556   \n",
       "16             0.673611            0.666667            0.680556   \n",
       "17             0.673611            0.666667            0.680556   \n",
       "18             0.673611            0.666667            0.680556   \n",
       "19             0.673611            0.666667            0.680556   \n",
       "20             0.673611            0.666667            0.680556   \n",
       "21             0.673611            0.666667            0.680556   \n",
       "22             0.673611            0.666667            0.680556   \n",
       "23             0.673611            0.666667            0.680556   \n",
       "24             0.673611            0.666667            0.680556   \n",
       "25             0.673611            0.666667            0.680556   \n",
       "26             0.673611            0.666667            0.680556   \n",
       "27             0.673611            0.666667            0.680556   \n",
       "28             0.673611            0.666667            0.680556   \n",
       "29             0.673611            0.666667            0.680556   \n",
       "..                  ...                 ...                 ...   \n",
       "528            0.770833            0.791667            0.756944   \n",
       "529            0.770833            0.777778            0.756944   \n",
       "530            0.770833            0.777778            0.756944   \n",
       "531            0.756944            0.777778            0.756944   \n",
       "532            0.756944            0.770833            0.756944   \n",
       "533            0.743056            0.770833            0.750000   \n",
       "534            0.743056            0.770833            0.750000   \n",
       "535            0.743056            0.770833            0.750000   \n",
       "536            0.743056            0.770833            0.736111   \n",
       "537            0.743056            0.770833            0.736111   \n",
       "538            0.729167            0.763889            0.736111   \n",
       "539            0.729167            0.763889            0.736111   \n",
       "540            0.791667            0.798611            0.770833   \n",
       "541            0.791667            0.791667            0.763889   \n",
       "542            0.791667            0.791667            0.763889   \n",
       "543            0.784722            0.791667            0.763889   \n",
       "544            0.784722            0.791667            0.756944   \n",
       "545            0.784722            0.791667            0.756944   \n",
       "546            0.770833            0.791667            0.756944   \n",
       "547            0.770833            0.777778            0.756944   \n",
       "548            0.770833            0.777778            0.756944   \n",
       "549            0.756944            0.777778            0.756944   \n",
       "550            0.756944            0.770833            0.756944   \n",
       "551            0.743056            0.770833            0.750000   \n",
       "552            0.743056            0.770833            0.750000   \n",
       "553            0.743056            0.770833            0.750000   \n",
       "554            0.743056            0.770833            0.736111   \n",
       "555            0.743056            0.770833            0.736111   \n",
       "556            0.729167            0.763889            0.736111   \n",
       "557            0.729167            0.763889            0.736111   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.715278            0.673611          0.681944         0.017236  \n",
       "1              0.715278            0.673611          0.681944         0.017236  \n",
       "2              0.715278            0.673611          0.681944         0.017236  \n",
       "3              0.715278            0.673611          0.681944         0.017236  \n",
       "4              0.715278            0.673611          0.681944         0.017236  \n",
       "5              0.715278            0.673611          0.681944         0.017236  \n",
       "6              0.715278            0.673611          0.681944         0.017236  \n",
       "7              0.715278            0.673611          0.681944         0.017236  \n",
       "8              0.715278            0.673611          0.681944         0.017236  \n",
       "9              0.715278            0.673611          0.681944         0.017236  \n",
       "10             0.715278            0.673611          0.681944         0.017236  \n",
       "11             0.715278            0.673611          0.681944         0.017236  \n",
       "12             0.715278            0.673611          0.681944         0.017236  \n",
       "13             0.715278            0.673611          0.681944         0.017236  \n",
       "14             0.715278            0.673611          0.681944         0.017236  \n",
       "15             0.715278            0.673611          0.681944         0.017236  \n",
       "16             0.715278            0.673611          0.681944         0.017236  \n",
       "17             0.715278            0.673611          0.681944         0.017236  \n",
       "18             0.715278            0.673611          0.681944         0.017236  \n",
       "19             0.715278            0.673611          0.681944         0.017236  \n",
       "20             0.715278            0.673611          0.681944         0.017236  \n",
       "21             0.715278            0.673611          0.681944         0.017236  \n",
       "22             0.715278            0.673611          0.681944         0.017236  \n",
       "23             0.715278            0.673611          0.681944         0.017236  \n",
       "24             0.715278            0.673611          0.681944         0.017236  \n",
       "25             0.715278            0.673611          0.681944         0.017236  \n",
       "26             0.715278            0.673611          0.681944         0.017236  \n",
       "27             0.715278            0.673611          0.681944         0.017236  \n",
       "28             0.715278            0.673611          0.681944         0.017236  \n",
       "29             0.715278            0.673611          0.681944         0.017236  \n",
       "..                  ...                 ...               ...              ...  \n",
       "528            0.770833            0.763889          0.770833         0.011620  \n",
       "529            0.770833            0.763889          0.768056         0.007082  \n",
       "530            0.770833            0.763889          0.768056         0.007082  \n",
       "531            0.770833            0.763889          0.765278         0.008099  \n",
       "532            0.763889            0.763889          0.762500         0.005197  \n",
       "533            0.763889            0.756944          0.756944         0.009821  \n",
       "534            0.763889            0.756944          0.756944         0.009821  \n",
       "535            0.750000            0.756944          0.754167         0.009420  \n",
       "536            0.750000            0.756944          0.751389         0.011948  \n",
       "537            0.750000            0.756944          0.751389         0.011948  \n",
       "538            0.750000            0.756944          0.747222         0.012880  \n",
       "539            0.750000            0.756944          0.747222         0.012880  \n",
       "540            0.770833            0.777778          0.781944         0.011283  \n",
       "541            0.770833            0.763889          0.776389         0.012729  \n",
       "542            0.770833            0.763889          0.776389         0.012729  \n",
       "543            0.770833            0.763889          0.775000         0.011283  \n",
       "544            0.770833            0.763889          0.773611         0.012880  \n",
       "545            0.770833            0.763889          0.773611         0.012880  \n",
       "546            0.770833            0.763889          0.770833         0.011620  \n",
       "547            0.770833            0.763889          0.768056         0.007082  \n",
       "548            0.770833            0.763889          0.768056         0.007082  \n",
       "549            0.770833            0.763889          0.765278         0.008099  \n",
       "550            0.763889            0.763889          0.762500         0.005197  \n",
       "551            0.763889            0.756944          0.756944         0.009821  \n",
       "552            0.763889            0.756944          0.756944         0.009821  \n",
       "553            0.750000            0.756944          0.754167         0.009420  \n",
       "554            0.750000            0.756944          0.751389         0.011948  \n",
       "555            0.750000            0.756944          0.751389         0.011948  \n",
       "556            0.750000            0.756944          0.747222         0.012880  \n",
       "557            0.750000            0.756944          0.747222         0.012880  \n",
       "\n",
       "[558 rows x 22 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_best_gs = gs.best_estimator_\n",
    "dtr_best_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_best_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Choose a number of different numeric columns to add to your model. Again do a grid search to find the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Use a completely different model that a decision tree. How high can you get the cross-validated score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning is helpful but not the most important thing\n",
    "The biggest gains with parameter tuning usually happen in the beginning. It then becomes harder and harder to improve the model after these initial gains. Your searches might become more and more granular for less and less gain. \n",
    "\n",
    "For most applications, finding hyper-parameters that are close enough to the best possible choice is usually good enough.\n",
    "\n",
    "# Hyper-parameter tuning is the last thing for machine learning\n",
    "Hyper-parameter tuning is important, but other things such as doing EDA and preparing your data for machine learning must come first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the decision tree\n",
    "Run the following command in the notebook `!pip install --user graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeClassifier(max_depth=3)\n",
    "dtr.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    706\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1332\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, quiet)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m    161\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x11586f2e8>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = export_graphviz(dtr, out_file=None, \n",
    "                           feature_names=['max_heart_rate'],\n",
    "                           filled=True, rounded=True,  special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "* You can parallelize the grid search to speed up the operations by setting **`n_jobs=-1`** during **`GridSearchCV`** instantiation.\n",
    "* By default the number of folds for cross validation is 3. Change this with **`cv`**\n",
    "* Use the **`RandomizedSearchCV`** instead which will randomly sample the hyper-parameter space. Read about the [comparison to grid search][1]. It can save lots of time and yield nearly as good results. By default, it searches 10 combinations.\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': depths, \n",
    "              'min_samples_split': splits}\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(dtr, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]), 'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'min_samples_split': 18}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054073484205193464"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
