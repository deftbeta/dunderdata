{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Decision boundaries\n",
    "For classification problems that involve exactly two predictor variables, a decision boundary may be plotted between the different classes. Any number of classes may be plotted in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.max_columns = 500\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv('data/heart.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n",
    "Use Matplotlib to plot. Color by purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(x='', y='', c='', data=, alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hb[[]].values\n",
    "y = hb[].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression(tol=.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(logr, X, y, cv=kf)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a decision boundary\n",
    "If we are modeling with just two predictor variables, then it is possible to plot a decision boundary and color the areas on the plot that correspond to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y):\n",
    "    X1 = X[:, 0]\n",
    "    X2 = X[:, 1]\n",
    "    x_min, x_max = X1.min() - 1, X1.max() + 1\n",
    "    y_min, y_max = X2.min() - 1, X2.max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    X_mesh = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "    Z = clf.predict(X_mesh)\n",
    "    Z, _ = pd.factorize(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    y, _ = pd.factorize(y)\n",
    "    ax.scatter(X1, X2, c=y, s=20, edgecolor='black')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(logr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All code at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "hb = pd.read_csv('.csv')\n",
    "X = hb[['', '']].values\n",
    "y = hb[''].values\n",
    "\n",
    "logr = LogisticRegression(tol=.00001)\n",
    "logr.fit(X, y)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(logr, X, y, cv=kf)\n",
    "print(\"CV Scores:\",  scores)\n",
    "print(f\"Mean CV accuracy is {scores.mean() :.3g} and STD is {scores.std() :.3g}\")\n",
    "\n",
    "plot_decision_boundary(logr, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
